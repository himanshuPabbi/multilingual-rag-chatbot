Groq-Accelerated Multilingual Healthcare RAG Chatbot

An advanced Retrieval-Augmented Generation (RAG) chatbot that leverages Groq LPU acceleration, LangChain, and FAISS vector search for lightning-fast, multilingual healthcare question answering.
The system integrates Groqâ€™s llama-3.1-8b-instant model for ultra-low-latency reasoning, combined with a local knowledge base for factual and explainable responses.

ğŸš€ Key Features

âœ… Groq LPU-Powered LLM â€” Uses llama-3.1-8b-instant via the Groq API for high-speed inference
âœ… Multilingual Support â€” Understands and responds in any language detected in user queries
âœ… Retrieval-Augmented Generation (RAG) â€” Answers are context-grounded using a local healthcare dataset
âœ… Persistent FAISS Vector Store â€” Efficient semantic retrieval of relevant document chunks
âœ… Batch Query Processing â€” Run and log multiple queries automatically to CSV
âœ… Interactive Chat Mode â€” Natural conversation interface using Streamlitâ€™s st.chat_message
âœ… Automatic Logging â€” Separate logs for chat and batch sessions stored as CSV files
âœ… Rebuildable Index â€” One-click FAISS reset for fresh knowledge base updates

ğŸ—‚ï¸ Project Structure
ğŸ“¦ groq-healthcare-rag-chatbot
â”‚
â”œâ”€â”€ knowledge_base/
â”‚   â””â”€â”€ healthcare_data.txt              # Your knowledge source for RAG (text file)
â”‚
â”œâ”€â”€ faiss_index/                         # Auto-generated FAISS vector database
â”‚
â”œâ”€â”€ interactive_chat_log.csv             # Logs interactive chat sessions
â”œâ”€â”€ batch_query_log.csv                  # Logs batch query results
â”‚
â”œâ”€â”€ .env                                 # Contains your GROQ_API_KEY
â”œâ”€â”€ requirements.txt                     # Python dependencies
â”œâ”€â”€ app.py                               # Main Streamlit app
â””â”€â”€ README.md                            # Project documentation

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
source venv/bin/activate   # For Linux/Mac
venv\Scripts\activate      # For Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Your .env File

Create a .env file in the root directory and add your Groq API key:

GROQ_API_KEY="gsk_your_actual_groq_api_key_here"

5ï¸âƒ£ Prepare Knowledge Base

Place your domain-specific text file inside the knowledge_base/ folder:

knowledge_base/
 â””â”€â”€ healthcare_data.txt


This file should contain factual healthcare-related information (guidelines, conditions, terms, etc.).

6ï¸âƒ£ Run the App
streamlit run app.py


Then open the link shown in your terminal (usually http://localhost:8501).

ğŸ’¬ Usage
ğŸ”¹ Interactive Chat Mode

Type questions in any language:

â€œWhat are the symptoms of diabetes?â€
â€œÂ¿CuÃ¡les son las causas del asma?â€
â€œà¤¦à¤¿à¤² à¤•à¥€ à¤¬à¥€à¤®à¤¾à¤°à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤ªà¥à¤°à¤®à¥à¤– à¤•à¤¾à¤°à¤£ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆà¤‚?â€

The chatbot retrieves the most relevant passages from the knowledge base, then responds concisely and accurately.

ğŸ”¹ Batch Query Mode

In the sidebar, enter multiple queries (one per line), for example:

What is hypertension?
What are the preventive measures for cancer?
Explain the role of clinical trials in drug development.


Click "Run Batch & Append to Log" to process all queries and save them in batch_query_log.csv.

ğŸ§© Rebuilding the Vector Store

If you update or replace your healthcare_data.txt, rebuild the FAISS index:

Open the app sidebar.

Click ğŸš¨ Rebuild FAISS Index.

The app will recreate embeddings and vector storage automatically.

ğŸ“Š Logging System
Log Type	File	Description
Interactive Chat	interactive_chat_log.csv	Logs each user-assistant message pair
Batch Queries	batch_query_log.csv	Logs all batch queries with timestamps and source context

Each log includes:

Timestamp

Query and Answer

Source Document Metadata

Snippet of Retrieved Context

Status (Success/Error)

ğŸ§  Technology Stack
Component	Library / API
LLM Backend	Groq API
 (llama-3.1-8b-instant)
Framework	LangChain

Embeddings	sentence-transformers/all-MiniLM-L6-v2
Vector Store	FAISS

Frontend	Streamlit

Logging	pandas, datetime, CSV storage
Configuration	.env, dotenv
ğŸ§° Requirements File Example

Include this in your requirements.txt if not already generated:

streamlit
langchain
langchain-groq
langchain-community
faiss-cpu
sentence-transformers
python-dotenv
pandas

ğŸ§¾ License

This project is open-source under the MIT License.
Youâ€™re free to use, modify, and distribute it with attribution.

ğŸ‘¨â€ğŸ’» Author

Himanshu Pabbi
AI & ML Foundation Researcher
ğŸ”— GitHub Profile https://github.com/himanshuPabbi
